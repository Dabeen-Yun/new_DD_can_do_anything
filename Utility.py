from Params import *

import numpy as np
import networkx as nx
import csv
import os
import json
import pandas as pd
import matplotlib.cm as cm
from matplotlib.patches import Rectangle
import cv2
import matplotlib.pyplot as plt
import pickle
import ast
import math

def get_vsg_id_from_coords(vsg_list, lat, lon, eps=1e-9):
    """
    ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ì…ë ¥ë°›ì•„ í•´ë‹¹ ìœ„ì¹˜ì˜ VSG IDë¥¼ ë°˜í™˜ (O(1))
    """
    for vsg in vsg_list:
        in_lat = (vsg.lat_min - eps) <= lat <= (vsg.lat_max + eps)
        in_lon = (vsg.lon_min - eps) <= lon <= (vsg.lon_max + eps)
        if in_lat and in_lon:
            return vsg.id

    input(f"No VSG found for coords lat={lat}, lon={lon}")
    return -1

# í•´ë‹¹ vnf tagê°€ 'vnf#'ì¸ì§€ í™•ì¸
def has_vnf_tag(x):
    if x is None:
        return False
    if isinstance(x, (list, tuple)):
        return any(isinstance(e, str) and 'vnf' in e.lower() for e in x)
    if isinstance(x, str):
        return 'vnf' in x.lower()
    return False

# í•´ë‹¹ vnf tagê°€ 'dst'ì¸ì§€ í™•ì¸
def has_dst_tag(x):
    if x is None:
        return False
    if isinstance(x, (list, tuple)):
        return any(isinstance(e, str) and 'dst' in e.lower() for e in x)
    if isinstance(x, str):
        return 'dst' in x.lower()
    return False

# vnf tagê°€ 'vnf#'ë¼ë©´, #ë§Œ ì¶”ì¶œ
def get_vnf_id_for_list(vnf_tag):
    """
    ê²½ë¡œ íƒœê·¸(ì˜ˆ: 'vnf1', ('src', 'vnf1'))ì—ì„œ VNF ë²ˆí˜¸(ì˜ˆ: '1')ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    :param vnf_tag: VNF ì •ë³´ê°€ ë‹´ê¸´ ë¬¸ìì—´ ë˜ëŠ” íŠœí”Œ.
    :return: VNF ë²ˆí˜¸('1', '2' ë“±)ë¥¼ ë‹´ì€ ë¬¸ìì—´, ë˜ëŠ” False (VNFê°€ ì—†ëŠ” ê²½ìš°).
    """
    # 1. vnf_tagê°€ íŠœí”Œì¼ ê²½ìš° (ì˜ˆ: ('src', 'vnf1'))
    if isinstance(vnf_tag, tuple):
        for item in vnf_tag:
            if isinstance(item, str) and item.startswith('vnf'):
                # 'vnf1'ì—ì„œ '1'ì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
                return item[3:]
        return False

    # 2. vnf_tagê°€ ë‹¨ì¼ ë¬¸ìì—´ì¼ ê²½ìš° (ì˜ˆ: 'vnf1' ë˜ëŠ” 'src')
    elif isinstance(vnf_tag, str) and vnf_tag.startswith('vnf'):
        return vnf_tag[3:]
    return False

def to_ecef_m(lat_deg, lon_deg, alt_m=ORBIT_ALTITUDE):
    """(deg, deg, m) -> ECEF (x,y,z) in meters (êµ¬í˜• ì§€êµ¬ ê·¼ì‚¬)"""
    lat = np.radians(lat_deg)
    lon = np.radians(lon_deg)
    r = R_EARTH_RADIUS + (alt_m if alt_m is not None else 0.0)
    x = r * np.cos(lat) * np.cos(lon)
    y = r * np.cos(lat) * np.sin(lon)
    z = r * np.sin(lat)
    return x, y, z

def filter_sats_with_xyz_m(vsg_sats, candidate_ids):
    """
    VSG ìœ„ì„± ë¦¬ìŠ¤íŠ¸ì—ì„œ í›„ë³´ IDë§Œ ì¶”ì¶œí•˜ê³  ECEF(m) ì¢Œí‘œê¹Œì§€ ì¤€ë¹„.
    sat.altê°€ kmë¼ë©´ alt_m = s.alt * 1000.0 ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.
    """
    cid = set(candidate_ids or [])
    rows = []

    for s in vsg_sats:
        if s.id in cid:
            alt_m = getattr(s, "alt", 0.0)  # meters ê°€ì •
            x, y, z = to_ecef_m(float(s.lat), float(s.lon), float(alt_m))
            rows.append((int(s.id), x, y, z))
    return rows

def best_pair_euclid_broadcast_m(src_arr, dst_arr):
    """
    src_arr: (n,4)[id,x,y,z] in meters, dst_arr: (m,4)
    ë¸Œë¡œë“œìºìŠ¤íŒ…ìœ¼ë¡œ ì œê³±ê±°ë¦¬ í–‰ë ¬ ê³„ì‚° í›„ ìµœì†Œ ìŒ.
    """
    sx = src_arr[:, 1][:, None]
    sy = src_arr[:, 2][:, None]
    sz = src_arr[:, 3][:, None]
    dx = dst_arr[:, 1][None, :]
    dy = dst_arr[:, 2][None, :]
    dz = dst_arr[:, 3][None, :]

    D2 = (sx - dx) ** 2 + (sy - dy) ** 2 + (sz - dz) ** 2
    k = int(np.argmin(D2))
    i, j = divmod(k, D2.shape[1])
    return int(src_arr[i, 0]), int(dst_arr[j, 0]), float(np.sqrt(D2[i, j]))  # ê±°ë¦¬(m)

def best_pair_euclid_ckdtree_m(src_arr, dst_arr):
    """
    í° ìŠ¤ì¼€ì¼ì—ì„œëŠ” KD-íŠ¸ë¦¬ë¡œ ìµœê·¼ì ‘ íƒìƒ‰ (meters).
    """
    from scipy.spatial import cKDTree
    tree = cKDTree(dst_arr[:, 1:4])  # xyz (meters)
    dists, idxs = tree.query(src_arr[:, 1:4], k=1)
    k = int(np.argmin(dists))
    return int(src_arr[k, 0]), int(dst_arr[int(idxs[k]), 0]), float(dists[k])  # ê±°ë¦¬(m)

# src sat í›„ë³´êµ°ê³¼ dst sat í›„ë³´êµ° ì¤‘ ì„œë¡œì˜ ê±°ë¦¬ê°€ ê°€ì¥ ê°€ê¹Œìš´ ì¡°í•© ë„ì¶œ
def get_src_dst_sat(src_vsg, dst_vsg, candidate_src_sats, candidate_dst_sats, all_vsg_list,
                    brute_threshold_pairs=200_000, prefer_ckdtree=True):
    """
    src_vsg/dst_vsg: VSG ì¸ë±ìŠ¤
    candidate_*_sats: ê³ ë ¤í•  ìœ„ì„± id ëª¨ìŒ
    ë°˜í™˜: (best_src_id, best_dst_id) ë˜ëŠ” return_distance=Trueë©´ (best_src_id, best_dst_id, best_dist_m)
    ì „ë¶€ ë¯¸í„°(m) ê¸°ì¤€.
    """
    src_rows = filter_sats_with_xyz_m(all_vsg_list[src_vsg].satellites, candidate_src_sats)
    dst_rows = filter_sats_with_xyz_m(all_vsg_list[dst_vsg].satellites, candidate_dst_sats)


    src_arr = np.array(src_rows, dtype=float)
    if src_arr.size == 0:
        print(src_rows)
    dst_arr = np.array(dst_rows, dtype=float)

    n, m = len(src_arr), len(dst_arr)
    pairs = n * m

    if pairs <= brute_threshold_pairs:
        sid, did, dist_m = best_pair_euclid_broadcast_m(src_arr, dst_arr)
    else:
        if prefer_ckdtree:
            try:
                sid, did, dist_m = best_pair_euclid_ckdtree_m(src_arr, dst_arr)
            except Exception:
                sid, did, dist_m = best_pair_euclid_broadcast_m(src_arr, dst_arr)
        else:
            sid, did, dist_m = best_pair_euclid_broadcast_m(src_arr, dst_arr)

    return (sid, did, dist_m)

# satellite ë§Œìœ¼ë¡œ êµ¬ì„±ëœ graphì— ì›í•˜ëŠ” gserver ì¶”ê°€ (gserver ê°„ ê²½ë¡œ ìƒì„±ì„ ë§‰ê¸° ìœ„í•´ í•´ë‹¹ gserverë§Œì„ ì¶”ê°€_
def create_temp_gserver_graph(G, all_gserver_list, all_vsg_list, gserver_id):
    TG_temp = G.copy()

    gserver = all_gserver_list[gserver_id]
    gserver_node_id = NUM_SATELLITES + gserver_id
    TG_temp.add_node(gserver_node_id, type="gserver", vsg_id=gserver.vsg_id)

    target_vsg = next((vsg for vsg in all_vsg_list if vsg.id == gserver.vsg_id), None)
    if target_vsg:
        for sat in target_vsg.satellites:
            tsl_delay_ms = sat.calculate_TSL_propagation_delay(gserver)
            # TSL ì—£ì§€ ì¶”ê°€ (weight=delay)
            TG_temp.add_edge(sat.id, gserver_node_id, weight=tsl_delay_ms, link_type='tsl')

    return TG_temp

# srcì™€ dst ê°„ ìµœë‹¨ ê²½ë¡œ ìƒì„±
def get_shortest_path(G, src_id, dst_id, graph=None):
    if graph is None:
        graph = G

    try:
        return nx.shortest_path(graph, src_id, dst_id)
    except (nx.NetworkXNoPath, nx.NodeNotFound):
        return None

# í•´ë‹¹ ìœ„ì„±ì˜ process queueì— ìŒ“ì—¬ìˆëŠ” VNF ì¢…ë¥˜ë³„ íŒ¨í‚· ì‚¬ì´ì¦ˆ(ë¡œë“œ)ë¥¼ ê³„ì‚°
def get_satellite_load(sat, all_gsfc_list):
    """
    :param sat: Satellite ê°ì²´
    :return: VNF ì¢…ë¥˜ë³„ ë¡œë“œ ë”•ì…”ë„ˆë¦¬(dict)
    """
    # VNF ì¢…ë¥˜ë³„ ë¡œë“œë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬: {'vnf1': load, 'vnf2': load, ...}
    vnf_load = {vnf_kind: 0 for vnf_kind in sat.vnf_list}

    # íì˜ ê° í•­ëª©ì€ [gsfc_id, vnf_idx, vnf_size] í˜•ì‹
    for item in sat.process_queue:
        if len(item) < 4: continue

        gsfc_id = item[0]
        vnf_idx = item[1]
        vnf_size = item[2]
        gsfc_type = item[3]

        try:
            # 1. GSFC ê°ì²´ì™€ VNF Sequenceë¥¼ ì‚¬ìš©í•˜ì—¬ VNF ì¢…ë¥˜ í™•ì¸
            gsfc = all_gsfc_list[gsfc_id]
            # vnf_sequenceê°€ SFCì˜ VNF ì¢…ë¥˜ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¼ê³  ê°€ì •
            vnf_kind = gsfc.vnf_sequence[vnf_idx]

            # ìœ„ì„±ì´ ì§€ì›í•˜ëŠ” VNF ì¢…ë¥˜ì¸ ê²½ìš°ì—ë§Œ ë¡œë“œ ëˆ„ì 
            if vnf_kind in vnf_load and isinstance(vnf_size, (int, float)):
                vnf_load[vnf_kind] += vnf_size

        except IndexError:
            # gsfc_idë‚˜ vnf_idxê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš° (ë°ì´í„° ë¶ˆì¼ì¹˜)
            continue

    # VNF ì¢…ë¥˜ë³„ ì „ì²´ ë¡œë“œ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    return vnf_load

def get_node_type(node_id, all_gserver_list, all_sat_list):
    if node_id >= NUM_SATELLITES:
        node_type = 'gserver'
        node = all_gserver_list[node_id - NUM_SATELLITES]
    else:
        node_type = 'satellite'
        node = all_sat_list[node_id]

    return node_type, node

# ê²½ë¡œ ë‚´ ìœ„ì„±ë“¤ì˜ id ì¶”ì¶œ
def sat_ids(path):
    """[sat_id, meta] ë˜ëŠ” sat_id ë¥¼ sat_id ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”"""
    ids = []
    for step in path:
        if isinstance(step, (list, tuple)):
            if len(step) == 0:
                continue
            ids.append(step[0])
        else:
            ids.append(step)
    return ids

# í•´ë‹¹ gsfcì—ì„œ ë‚¨ì€ ê²½ë¡œ ì¶”ì¶œ
def get_remain_path(gsfc):
    return gsfc.satellite_path[gsfc.cur_path_id:]

GSFC_LOG_HEADER = [
    "time_ms",
    "mode",
    "gsfc_id",
    "gsfc_type",
    "tolerance_delay_ms",
    "is_succeed",
    "is_dropped",
    "event",
    "vnf_sequence",
    "src_vsg",
    "dst_vsg",
    "gsfc_flow_rule",
    "vsg_path",
    "satellite_path",
    "processed_satellite_path",
    "state",
    "remaining ongoing time slot",
    "process delay",
    "queueing delay",
    "transmitting delay",
    "propagation delay",
    "total delay",
    "additional_path"
]

def init_gsfc_csv_log(csv_dir_path, mode):
    os.makedirs(csv_dir_path, exist_ok=True)
    file_path = os.path.join(csv_dir_path, f"{mode}_gsfc_log.csv")

    with open(file_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(GSFC_LOG_HEADER)

    return file_path

def to_str(x):
    # ìˆ«ì/ë¬¸ìì—´ì€ ê·¸ëŒ€ë¡œ, ë‚˜ë¨¸ì§€ëŠ” jsonìœ¼ë¡œ
    if isinstance(x, (int, float, str)) or x is None:
        return x
    try:
        return json.dumps(x, ensure_ascii=False)
    except TypeError:
        return str(x)

def write_gsfc_csv_log(file_path, time_ms, gsfc, event):
    # event: "INIT_PATH", "PROCESS", "QUEUE", "TRANSMIT","PROPAGATE", 'DONE", "DROP"
    if not file_path:
        return

    processed_satellite_path = gsfc.satellite_path[:gsfc.cur_path_id]

    row = [
        time_ms,
        getattr(gsfc, "mode", ""),
        getattr(gsfc, "id", None),
        getattr(gsfc, "gsfc_type", None),
        getattr(gsfc, "tolerance_time_ms", None),
        getattr(gsfc, "is_succeed", False),
        getattr(gsfc, "is_dropped", False),
        event,
        to_str(getattr(gsfc, "vnf_sequence", [])),
        getattr(gsfc, "src_vsg_id", ""),
        getattr(gsfc, "dst_vsg_id", ""),
        to_str(getattr(gsfc, "gsfc_flow_rule", [])),
        to_str(getattr(gsfc, "vsg_path", [])),
        to_str(getattr(gsfc, "satellite_path", [])),
        # to_str(getattr(gsfc, f"satellite_path{gsfc.cur_path_id}", [])),
        processed_satellite_path,
        to_str(getattr(gsfc, "state", -1)),
        to_str(getattr(gsfc, "DH_remaining_ongoing_time_slot", -1)),
        to_str(getattr(gsfc, "proc_delay_ms", 0)),
        # to_str(getattr(gsfc, "queue_delay_ms", 0)),
        to_str(getattr(gsfc, "proc_queue_delay_ms", 0)),
        to_str(getattr(gsfc, "trans_delay_ms", 0)),
        to_str(getattr(gsfc, "prop_delay_ms", 0)),
        to_str(getattr(gsfc, "proc_delay_ms", 0) +
               getattr(gsfc, "proc_queue_delay_ms", 0) +
               getattr(gsfc, "queue_delay_ms", 0) +
               getattr(gsfc, "trans_delay_ms", 0) +
               getattr(gsfc, "prop_delay_ms", 0)),
        getattr(gsfc, "additional_path", 0)
    ]

    with open(file_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(row)

    setattr(gsfc, "additional_path", 0)

def calculate_additional_path_stats(file_path):
    if not os.path.exists(file_path):
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {file_path}")
        return

    try:
        df = pd.read_csv(file_path)
        df['additional_path'] = pd.to_numeric(df['additional_path'], errors='coerce').fillna(0)

        # ì´ëŸ‰ ê³„ì‚° (í•©ê³„)
        total_additional_path = df['additional_path'].sum()

        # í‰ê·  ê³„ì‚° (ê²°ì¸¡ê°’ ì œì™¸ í›„ í‰ê· )
        # ì „ì²´ í–‰ì— ëŒ€í•œ í‰ê· 
        average_additional_path = df['additional_path'].mean()

        print(f"--- CSV íŒŒì¼ ë¶„ì„ ê²°ê³¼: {file_path} ---")
        print(f"ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {len(df)}")
        print(f"'additional_path' ì´ëŸ‰ (í•©ê³„): {total_additional_path}")
        print(f"'additional_path' í‰ê· : {average_additional_path:.4f}")

    except Exception as e:
        print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def calculate_success_hop_stats(file_path):
    if not os.path.exists(file_path):
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {file_path}")
        return

    try:
        df = pd.read_csv(file_path)

        # is_succeed ì»¬ëŸ¼ì„ boolë¡œ ì •ê·œí™”
        succeed_col = df['is_succeed']

        if succeed_col.dtype == bool:
            success_df = df[df['is_succeed']]
        else:
            # ë¬¸ìì—´/ìˆ«ì í˜•íƒœì¸ ê²½ìš° ('True', 'False', 1, 0 ë“±)
            success_df = df[succeed_col.astype(str).str.lower().isin(['true', '1', 'yes'])]

        total_hop_count = 0

        if success_df.empty:
            print(f"--- CSV íŒŒì¼ ë¶„ì„ ê²°ê³¼: {file_path} ---")
            print("ì„±ê³µí•œ(success=True) GSFCê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        def count_hops(path_val):
            # ê²°ì¸¡ ì²˜ë¦¬
            if pd.isna(path_val):
                return 0

            # CSV ì½ì–´ì˜¤ë©´ ë³´í†µ ë¬¸ìì—´ì´ë¯€ë¡œ literal_evalë¡œ íŒŒì‹±
            if isinstance(path_val, str):
                try:
                    parsed = ast.literal_eval(path_val)
                except Exception:
                    # íŒŒì‹± ì‹¤íŒ¨í•˜ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬
                    return 0
            else:
                parsed = path_val

            # ìš°ë¦¬ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœ: [[38, "src"], [27, "vnf1"], ...]
            if isinstance(parsed, list):
                return len(parsed)  # ìš”ì†Œ ê°œìˆ˜ = hop count (ë…¸ë“œ ê°œìˆ˜ ê¸°ì¤€)
                # ë§Œì•½ ë§í¬ ê°œìˆ˜ ê¸°ì¤€ hop ì„ ì›í•˜ë©´ len(parsed) - 1 ë¡œ ë°”ê¾¸ë©´ ë¨

            return 0

        # hop_count ì»¬ëŸ¼ ì¶”ê°€
        success_df = success_df.copy()
        success_df['hop_count'] = success_df['satellite_path'].apply(count_hops)
        total_hop_count += success_df['hop_count']

        total_hops = success_df['hop_count'].sum()
        avg_hops = success_df['hop_count'].mean()
        max_hops = success_df['hop_count'].max()
        min_hops = success_df['hop_count'].min()

        print(f"--- CSV íŒŒì¼ ë¶„ì„ ê²°ê³¼ (success == True): {file_path} ---")
        print(f"ì„±ê³µí•œ GSFC ë ˆì½”ë“œ ìˆ˜: {len(success_df)}")
        print(f"ì´ hop ìˆ˜ í•©ê³„: {total_hops}")
        print(f"í‰ê·  hop ìˆ˜: {avg_hops:.4f}")
        print(f"ìµœì†Œ hop ìˆ˜: {min_hops}")
        print(f"ìµœëŒ€ hop ìˆ˜: {max_hops}")

        # í•„ìš”í•˜ë©´ ê°œë³„ hop_count ë¶„í¬ë¥¼ ë³´ê³  ì‹¶ì„ ë•Œ:
        # print(success_df[['gsfc_id', 'satellite_path', 'hop_count']].head())

    except Exception as e:
        print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

SATELLITE_LOG_HEADER = [
    "time_ms",
    "mode",
    "sat_id",
    "lon",
    "lat",
    "vnf list",
    "adjacent sat index",
    "process queue size",
    "process queue",
]

def init_sat_csv_log(csv_dir_path, mode):
    os.makedirs(csv_dir_path, exist_ok=True)
    file_path = os.path.join(csv_dir_path, f"{mode}_sat_log.csv")

    with open(file_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(SATELLITE_LOG_HEADER)

    return file_path

def write_sat_csv_log(sat):
    if not sat.sat_log_path:
        return

    process_queue = getattr(sat, "process_queue", [])

    row = [
        getattr(sat, "time", -1),
        getattr(sat, "mode", ""),
        getattr(sat, "id", -1),
        getattr(sat, "lon", 0),
        getattr(sat, "lat", 0),
        getattr(sat, "vnf_list", []),
        getattr(sat, "adj_sat_index_list", []),
        len(process_queue),
        process_queue,
    ]

    with open(sat.sat_log_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(row)

VSG_LOG_HEADER = [
    "time_ms",
    "mode",
    "vsg_id",
    "lon min",
    "lat min",
    "assigned vnfs",
    "satellites"
]

def init_vsg_csv_log(csv_dir_path, mode):
    os.makedirs(csv_dir_path, exist_ok=True)
    file_path = os.path.join(csv_dir_path, f"{mode}_vsg_log.csv")

    with open(file_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(VSG_LOG_HEADER)

    return file_path

def write_vsg_csv_log(vsg):
    if not vsg.vsg_log_path:
        return

    satellite_ids = [sat.id for sat in getattr(vsg, "satellites", [])]

    row = [
        getattr(vsg, "time", -1),
        getattr(vsg, "mode", ""),
        getattr(vsg, "id", -1),
        getattr(vsg, "lon_min", 0),
        getattr(vsg, "lat_min", 0),
        getattr(vsg, "assigned_vnfs", []),
        satellite_ids # satellite idx
    ]

    with open(vsg.vsg_log_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(row)

def save_networkx_graph(G, file_path):
    """NetworkX ê·¸ë˜í”„ ê°ì²´ë¥¼ Pickle íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'wb') as f:
            pickle.dump(G, f)
        print(f"[INFO] NetworkX graph saved to {file_path}")
    except Exception as e:
        print(f"[ERROR] Failed to save graph: {e}")

def load_networkx_graph(file_path):
    """Pickle íŒŒì¼ì—ì„œ NetworkX ê·¸ë˜í”„ ê°ì²´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'rb') as f:
            G = pickle.load(f)
        print(f"[INFO] NetworkX graph loaded from {file_path}")
        return G
    except FileNotFoundError:
        print(f"[ERROR] Graph file not found: {file_path}")
        return None
    except Exception as e:
        print(f"[ERROR] Failed to load graph: {e}")
        return None

def load_all_gsfc_logs(modes, lon_steps, seed_nums, data_rate_pairs, base_results_dir="./results"):
    """
    results/{NUM_GSFC*NUM_ITERATIONS}/{mode}/{sat_Mbps}sat_{gs_Mbps}gs/gsfc_log_{mode}.csv
    êµ¬ì¡°ë¡œ ì €ì¥ëœ ë¡œê·¸ë¥¼ ëª¨ë‘ ì½ì–´ì„œ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹œë‹¤.
    """
    dfs = []
    for seed_num in seed_nums:
        for sat_rate, gs_rate in data_rate_pairs:
            sat_mbps = sat_rate / 1e6
            gs_mbps = gs_rate / 1e6
            data_rate_label = f"{sat_mbps}sat_{gs_mbps}gs"
            for lon_step in lon_steps:
                for mode in modes:
                    csv_dir = f"{base_results_dir}/run_{seed_num}/{lon_step}_{NUM_GSFC*NUM_ITERATIONS}/{mode}/{data_rate_label}/"
                    csv_path = f"{csv_dir}{mode}_gsfc_log.csv"

                    if not os.path.exists(csv_path):
                        print(f"[WARN] CSV not found: {csv_path}")
                        continue

                    df = pd.read_csv(csv_path)

                    # í˜¹ì‹œ mode ì»¬ëŸ¼ ì—†ìœ¼ë©´ ë¶™ì—¬ì£¼ê¸°
                    if "mode" not in df.columns:
                        df["mode"] = mode

                    # í˜¹ì‹œ lon_step ì»¬ëŸ¼ ì—†ìœ¼ë©´ ë¶™ì—¬ì£¼ê¸°
                    if "lon_step" not in df.columns:
                        df["lon_step"] = lon_step

                    if "seed_idx" not in df.columns:
                        df["seed_idx"] = seed_num

                    df["sat_rate_bps"] = sat_rate
                    df["gs_rate_bps"] = gs_rate
                    df["data_rate_label"] = data_rate_label

                    dfs.append(df)

    if not dfs:
        print("[ERROR] No CSV loaded")
        return pd.DataFrame()

    df_all = pd.concat(dfs, ignore_index=True)
    return df_all

def preprocess_gsfc_logs(df_all):
    """
    - is_succeed == Trueì¸ í–‰ë§Œ ì‚¬ìš©
    - ë™ì¼ GSFCì— ëŒ€í•´ ë§ˆì§€ë§‰ time_ms (ì™„ë£Œ ì‹œì )ë§Œ ë‚¨ê¸°ê¸°
    - delay ìˆ«ìí˜• ë³€í™˜, e2e_delay_ms ê³„ì‚°
    """
    if df_all.empty:
        return df_all

    # is_succeed / is_dropped ì •ë¦¬
    for col in ["is_succeed", "is_dropped"]:
        if col in df_all.columns and df_all[col].dtype == object:
            df_all[col] = df_all[col].astype(str).str.lower().isin(["true", "1", "yes"])

    # ìˆ«ìí˜• ì»¬ëŸ¼ ë³€í™˜
    numeric_cols = [
        "time_ms",
        "process delay",
        "queueing delay",
        "transmitting delay",
        "propagation delay",
    ]
    for col in numeric_cols:
        if col in df_all.columns:
            df_all[col] = pd.to_numeric(df_all[col], errors="coerce")

    # e2e_delay_ms (total delay) ë¶ˆëŸ¬ì˜¤ê¸°
    df_all.get("total delay", 0)

    # ì„±ê³µí•œ GSFCë§Œ ì‚¬ìš©
    df_succ = df_all[df_all["is_succeed"] == True].copy()

    if df_succ.empty:
        print("[WARN] No successful GSFCs found")
        return df_succ

    # ê°™ì€ GSFCê°€ ì—¬ëŸ¬ time_msì— ì°í˜€ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ, ë§ˆì§€ë§‰ ì‹œì ë§Œ ì‚¬ìš©
    # key: mode, data_rate_label, gsfc_id
    sort_cols = []
    for c in ["mode", "seed_idx", "data_rate_label", "gsfc_id", "time_ms"]:
        if c in df_succ.columns:
            sort_cols.append(c)

    if "time_ms" in sort_cols:
        df_succ = df_succ.sort_values(sort_cols)
        group_cols = [c for c in ["mode", "seed_idx", "data_rate_label", "gsfc_id"] if c in df_succ.columns]
        if group_cols:
            df_succ = df_succ.groupby(group_cols, as_index=False).tail(1)

    return df_succ

def plot_e2e_vs_data_rate(df_succ, lon_steps, seed_nums, out_path="e2e_vs_data_rate_per_mode.png"):
    """
    ê° modeì— ëŒ€í•´ data_rate_pairì— ë”°ë¥¸ E2E delay ë³€í™”ë¥¼ ë¼ì¸ ê·¸ë˜í”„ë¡œ.
    """
    if df_succ.empty:
        print("[WARN] df_succ is empty, skip plot_e2e_vs_data_rate")
        return

    modes = sorted(df_succ["mode"].dropna().unique())
    # data_rate_label ìˆœì„œë¥¼ sat_rate ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    # (sat_rate_bpsê°€ ë“¤ì–´ìˆë‹¤ëŠ” ê°€ì •)
    df_succ["sat_rate_mbps"] = df_succ["sat_rate_bps"] / 1e6

    # label ìˆœì„œ
    label_order = (
        df_succ[["data_rate_label", "sat_rate_mbps"]]
        .drop_duplicates()
        .sort_values("sat_rate_mbps")
    )
    labels = label_order["data_rate_label"].tolist()

    # ğŸ”¥ í•µì‹¬: mode, lon_step, data_rate_label ë‹¨ìœ„ë¡œ í‰ê·  E2E delay ê³„ì‚°
    df_agg = (
        df_succ
        .groupby(["mode", "lon_step", "data_rate_label"])["total delay"]
        .mean()
        .reset_index()
    )

    plt.figure()
    for lon_step in lon_steps:
        for mode in modes:
            df_line = df_agg[
                (df_agg["mode"] == mode) & (df_agg["lon_step"] == lon_step)
                ]

            # data_rate_label ìˆœì„œ ì¬ì •ë ¬
            df_line = (
                df_line
                .set_index("data_rate_label")
                .reindex(labels)
            )

            plt.plot(
                labels,
                df_line["total delay"].values,
                marker="o",
                label=f"{mode}, lon_step={lon_step}"
            )

    plt.xlabel("Data rate pair (sat_Mbps / gs_Mbps)")
    plt.ylabel("Average E2E delay [ms]")
    plt.title("E2E delay vs data_rate_pair (per mode, per lon_step)")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.savefig(out_path, dpi=300)
    # plt.show()
    print(f"[INFO] Saved {out_path}")

def plot_e2e_vs_mode(df_succ, out_dir="./", prefix="e2e_vs_mode_"):
    """
    ê° data_rate_pairì— ëŒ€í•´, modeë³„ E2E delay í‰ê· ì„ bar ê·¸ë˜í”„ë¡œ.
    data_rate_pairê°€ ì—¬ëŸ¬ ê°œë©´, pairë³„ë¡œ íŒŒì¼ì„ ì—¬ëŸ¬ ê°œ ë§Œë“ ë‹¤.
    """
    if df_succ.empty:
        print("[WARN] df_succ is empty, skip plot_e2e_vs_mode")
        return

    os.makedirs(out_dir, exist_ok=True)

    delay_components = [
        "process delay",
        "queueing delay",
        "transmitting delay",
        "propagation delay",
    ]

    # data_rate_label ë‹¨ìœ„ë¡œ loop
    for data_rate_label, df_pair in df_succ.groupby("data_rate_label"):
        # ğŸ”¥ 1ë‹¨ê³„: run_idx(ë˜ëŠ” seed)ê°€ ìˆìœ¼ë©´ run ë‹¨ìœ„ í‰ê· , ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ìœ ì§€
        if "run_idx" in df_pair.columns:
            # (run_idx, mode, lon_step) ë³„ë¡œ ë¨¼ì € í‰ê· 
            df_run = (
                df_pair
                .groupby(["run_idx", "mode", "lon_step"])[delay_components]
                .mean()
                .reset_index()
            )
            # ê·¸ ë‹¤ìŒ, run_idxë¥¼ ë‚ ë¦¬ê³  (mode, lon_step) ë³„ë¡œ ë‹¤ì‹œ í‰ê·  â†’ seed í‰ê· 
            df_agg = (
                df_run
                .groupby(["mode", "lon_step"])[delay_components]
                .mean()
            )
        else:
            # run_idx ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´, ê¸°ì¡´ì²˜ëŸ¼ ì „ì²´ ìƒ˜í”Œì— ëŒ€í•œ í‰ê·  (seedë³„ ê°€ì¤‘ í‰ê· )
            df_agg = df_pair.groupby(["mode", "lon_step"])[delay_components].mean()

        # ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆëœë‹ˆë‹¤.
        if df_agg.empty:
            print(f"[WARN] No aggregated data for data_rate_label {data_rate_label}")
            continue

        # ì¸ë±ìŠ¤ ì •ë ¬ (mode, lat_step ìˆœ)
        df_agg = df_agg.sort_index()  # MultiIndex: (mode, lat_step)

        # xì¶•ì— ì“¸ ë¼ë²¨: "mode\nlat{lat_step}"
        idx_tuples = df_agg.index.tolist()
        labels = [f"{mode}\nlat{lat_step}" for (mode, lat_step) in idx_tuples]

        x = np.arange(len(labels))

        plt.figure(figsize=(max(8, len(labels) * 0.6), 6))
        current_bottom = np.zeros(len(labels))
        bar_containers = {}

        for i, component in enumerate(delay_components):
            # ië²ˆì§¸ ì»´í¬ë„ŒíŠ¸ì˜ í‰ê·  ì§€ì—° ê°’ (Numpy Array)
            delay_values = df_agg[component].values

            # barë¥¼ ê·¸ë¦¬ê³ , ê·¸ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ì£¼ì„(Annotation)ì— ì‚¬ìš©
            bars = plt.bar(
                x,
                delay_values,
                label=component.replace(' delay', '').title(),  # ë²”ë¡€ë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ ìˆ˜ì •
                bottom=current_bottom
            )
            bar_containers[component] = bars

            # ë‹¤ìŒ ë§‰ëŒ€ë¥¼ ìœ„í•´ í˜„ì¬ ë§‰ëŒ€ ë†’ì´ë¥¼ current_bottomì— ë”í•©ë‹ˆë‹¤ (ëˆ„ì )
            current_bottom += delay_values

        def autolabel_stack(bars, segment_vals, current_bottom_vals):
            for bar, val, bottom_start in zip(bars, segment_vals, current_bottom_vals):
                if val > 0.1:  # ê°’ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ìƒëµ
                    y_center = bottom_start + val / 2.0
                    plt.text(bar.get_x() + bar.get_width() / 2.0, y_center,
                             f"{val:.1f}", ha="center", va="center", fontsize=8)

        current_bottom_annotation = np.zeros(len(labels))

        for i, component in enumerate(delay_components):
            delay_values = df_agg[component].values
            bars = bar_containers[component]

            # ì£¼ì„ í—¬í¼ í•¨ìˆ˜ í˜¸ì¶œ
            autolabel_stack(bars, delay_values, current_bottom_annotation)

            # ë‹¤ìŒ ì£¼ì„ì„ ìœ„í•´ ëˆ„ì  í•© ì—…ë°ì´íŠ¸
            current_bottom_annotation += delay_values

        plt.xticks(x, labels, rotation=30)
        plt.ylabel("Average E2E Delay [ms]")
        plt.title(f"Average E2E Delay Breakdown by Mode (data_rate={data_rate_label})")
        plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1))
        plt.grid(True, axis="y", linestyle='--', alpha=0.6)
        plt.tight_layout()

        filename = f"{prefix}{data_rate_label}.png"
        out_path = os.path.join(out_dir, filename)

        plt.savefig(out_path, dpi=300)
        plt.close()  # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ í”Œë¡¯ ë‹«ê¸°
        print(f"[INFO] Saved {out_path}")

def plot_e2e_summary(modes, lon_steps, seed_nums, data_rate_pairs, base_results_dir="./results"):
    """
    main.pyì—ì„œ ì‹œë®¬ ë‹¤ ëˆ ë’¤ì— í•œ ë²ˆ í˜¸ì¶œ:
    - ëª¨ë“  mode Ã— data_rate_pair CSVë¥¼ ì½ê³ 
    - is_succeed == True + ë§ˆì§€ë§‰ ì‹œì  rowë§Œ ì‚¬ìš©í•´ì„œ
    - 1) mode ê³ ì •, data_rate_pair ë¹„êµ (ë¼ì¸ ê·¸ë˜í”„)
    - 2) data_rate_pair ê³ ì •, mode ë¹„êµ (bar ê·¸ë˜í”„)
    """
    df_all = load_all_gsfc_logs(modes, lon_steps, seed_nums, data_rate_pairs, base_results_dir)
    df_succ = preprocess_gsfc_logs(df_all)

    if df_succ.empty:
        print("[WARN] No successful GSFCs to plot")
        return

    # out_dirì€ ê²°ê³¼ ìœ„ì¹˜ í†µì¼í•´ì„œ ê´€ë¦¬
    out_dir = os.path.join(base_results_dir, "plots")
    os.makedirs(out_dir, exist_ok=True)

    # 1) [ëª¨ë“œë³„] data_rate_pair ë¹„êµ
    plot_e2e_vs_data_rate(
        df_succ,
        lon_steps,
        seed_nums,
        out_path=os.path.join(out_dir, "e2e_vs_data_rate_per_mode.png"),
    )

    # 2) [data_rate_pairë³„] mode ë¹„êµ
    plot_e2e_vs_mode(
        df_succ,
        out_dir=out_dir,
        prefix="e2e_vs_mode_",
    )

# íŒŒì‹± í—¬í¼ í•¨ìˆ˜ (CSVì˜ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜)
def safe_eval(s):
    """CSVì— ì €ì¥ëœ ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ë¥¼ íŒŒì´ì¬ ê°ì²´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    if isinstance(s, (list, dict)):
        return s
    if pd.isna(s) or s == "":
        return None
    try:
        # json.loads ëŒ€ì‹  evalì„ ì‚¬ìš©í•˜ì—¬ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë„ íŒŒì‹± (ì£¼ì˜: ë³´ì•ˆì— ì·¨ì•½í•  ìˆ˜ ìˆìœ¼ë‚˜ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œëŠ” í—ˆìš©)
        return eval(str(s))
    except:
        return s

def load_data_for_time_tick(t, mode, csv_dir_path):
    """
    íŠ¹ì • ì‹œê°„(t)ê³¼ ëª¨ë“œ(mode)ì— ëŒ€í•œ GSFC, SAT, VSG ë°ì´í„°ë¥¼ CSVì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
    """

    # íŒŒì¼ ê²½ë¡œ ì •ì˜
    gsfc_log_path = os.path.join(csv_dir_path, f"{mode}_gsfc_log.csv")
    sat_log_path = os.path.join(csv_dir_path, f"{mode}_sat_log.csv")
    vsg_log_path = os.path.join(csv_dir_path, f"{mode}_vsg_log.csv")

    # 1. GSFC ë°ì´í„° ë¡œë“œ
    try:
        df_gsfc = pd.read_csv(gsfc_log_path)
        # t ì‹œì ì˜ ê°€ì¥ ìµœê·¼ ê²½ë¡œ (INIT_PATH ë˜ëŠ” ìµœì‹  ì—…ë°ì´íŠ¸) ê¸°ë¡ì„ ì°¾ê¸° ìœ„í•´ í•„í„°ë§
        gsfc_data = df_gsfc[df_gsfc['time_ms'] <= t].sort_values(by='time_ms', ascending=False).drop_duplicates(
            subset=['gsfc_id'], keep='first').copy()
    except FileNotFoundError:
        print(f"[ERROR] GSFC log not found: {gsfc_log_path}")
        gsfc_data = pd.DataFrame()
    except Exception as e:
        print(f"[ERROR] Reading GSFC log failed: {e}")
        gsfc_data = pd.DataFrame()

    # 2. SAT ë°ì´í„° ë¡œë“œ (t ì‹œì ì˜ ë°ì´í„°)
    try:
        df_sat = pd.read_csv(sat_log_path)
        # t ì‹œì ì˜ ë°ì´í„°ë§Œ ì‚¬ìš© (ìœ„ì„± ìœ„ì¹˜, VNF, ì¸ì ‘ ìœ„ì„± ëª©ë¡)
        sat_data = df_sat[df_sat['time_ms'] == t].copy()
        # sat_dataê°€ ë¹„ì–´ìˆë‹¤ë©´, t=0 ì‹œì ì˜ ì´ˆê¸° í† í´ë¡œì§€ë¥¼ ì°¾ì•„ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ t=t ë°ì´í„°ë§Œ ë¡œë“œ)
    except FileNotFoundError:
        print(f"[ERROR] SAT log not found: {sat_log_path}")
        sat_data = pd.DataFrame()
    except Exception as e:
        print(f"[ERROR] Reading SAT log failed: {e}")
        sat_data = pd.DataFrame()

    # 3. VSG ë°ì´í„° ë¡œë“œ (t ì‹œì ì˜ ë°ì´í„°)
    try:
        df_vsg = pd.read_csv(vsg_log_path)
        # t ì‹œì ì˜ ë°ì´í„°ë§Œ ì‚¬ìš© (ê²½ê³„, í• ë‹¹ VNF)
        vsg_data = df_vsg[df_vsg['time_ms'] == t].copy()
    except FileNotFoundError:
        print(f"[ERROR] VSG log not found: {vsg_log_path}")
        vsg_data = pd.DataFrame()
    except Exception as e:
        print(f"[ERROR] Reading VSG log failed: {e}")
        vsg_data = pd.DataFrame()

    # 4. ë°ì´í„° êµ¬ì¡° ë³€í™˜ (IDë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)
    # GSFC ë°ì´í„° (í•˜ë‚˜ì˜ GSFC IDë§Œ ì¶”ì )
    gsfc_dict = {}
    if not gsfc_data.empty:
        # 'satellite_path'ì™€ 'processed_satellite_path'ë¥¼ ê°ì²´ë¡œ ë³€í™˜
        gsfc_data['satellite_path'] = gsfc_data['satellite_path'].apply(safe_eval)
        gsfc_data['processed_satellite_path'] = gsfc_data['processed_satellite_path'].apply(safe_eval)
        gsfc_dict = gsfc_data.set_index('gsfc_id', drop=False).to_dict('index')

    # ìœ„ì„± ë°ì´í„°
    sat_list_dict = {}
    if not sat_data.empty:
        # VNF ë¦¬ìŠ¤íŠ¸ì™€ ì¸ì ‘ ëª©ë¡ íŒŒì‹±
        sat_data['vnf list'] = sat_data['vnf list'].apply(safe_eval)
        sat_data['adjacent sat index'] = sat_data['adjacent sat index'].apply(safe_eval)
        sat_list_dict = sat_data.set_index('sat_id', drop=False).to_dict('index')

    # VSG ë°ì´í„°
    vsg_list_dict = {}
    if not vsg_data.empty:
        # í• ë‹¹ VNFì™€ ìœ„ì„± ëª©ë¡ íŒŒì‹±
        vsg_data['assigned vnfs'] = vsg_data['assigned vnfs'].apply(safe_eval)
        vsg_data['satellites'] = vsg_data['satellites'].apply(safe_eval)  # ì—¬ê¸°ì— sat_id ë¦¬ìŠ¤íŠ¸ê°€ ë“¤ì–´ìˆë‹¤ê³  ê°€ì •
        vsg_list_dict = vsg_data.set_index('vsg_id', drop=False).to_dict('index')

    return gsfc_dict, sat_list_dict, vsg_list_dict

def safe_load_path(raw):
    if isinstance(raw, list):
        return raw
    if isinstance(raw, str):
        raw = raw.strip()
        if raw == "" or raw == "[]":
            return []
        try:
            return json.loads(raw)
        except:
            print("[WARN] json.loads ì‹¤íŒ¨ â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜", raw)
            return []
    return []

def animate_one_gsfc(gsfc_id, modes, csv_dir_path):
    for mode in modes:
        video_writer = None
        video_fps = 30
        video_path = os.path.join(csv_dir_path, f"{mode}_gsfc{gsfc_id}_network_constellation.mp4")

        graph_file_path = os.path.join(csv_dir_path, f"{mode}_network_G.pkl")
        G = load_networkx_graph(graph_file_path)

        print(f"[INFO] Starting animation for mode {mode}, GSFC {gsfc_id}")

        try:
            df_gsfc_check = pd.read_csv(os.path.join(csv_dir_path, f"{mode}_gsfc_log.csv"))
            MAX_T = df_gsfc_check['time_ms'].max()
        except:
            MAX_T = 50

        for t in range(MAX_T):
            gsfc_dict, sat_dict, vsg_dict = load_data_for_time_tick(t, mode, csv_dir_path)

            gsfc_record = gsfc_dict.get(gsfc_id)

            sat_list = list(sat_dict.values())
            vsg_list = list(vsg_dict.values())

            # ì»¬ëŸ¬ë§µ ìƒì„± (VSGë³„ ìƒ‰ìƒ)
            cmap = cm.get_cmap('tab20', len(vsg_list))
            vsg_colors = {vsg['vsg_id']: cmap(vsg['vsg_id']) for vsg in vsg_list}

            fig = plt.figure(figsize=(24, 12))
            ax = plt.gca()

            # 0. VSG ì˜ì—­ í‘œí˜„
            for vsg in vsg_list:
                rect = Rectangle((vsg['lon min'], vsg['lat min']), LON_STEP, LAT_STEP,
                                 linewidth=0.8, edgecolor=vsg_colors[vsg['vsg_id']],
                                 facecolor=vsg_colors[vsg['vsg_id']],
                                 alpha=0.4, zorder=0)
                ax.add_patch(rect)

                if vsg['assigned vnfs'] and len(vsg['assigned vnfs']) > 1:
                    ax.annotate(f"VNF {vsg['assigned vnfs']}", (vsg['lon min'] + 1, vsg['lat min'] + 1),
                                 fontsize=13, color='black', alpha=0.8, zorder=12)

            # 1. ISL (adjacency edge) ê·¸ë¦¬ê¸°
            sat_positions = {sat['sat_id']: (sat['lon'], sat['lat']) for sat in sat_list}

            for sat in sat_list:
                # adj_sat_index_list ëŒ€ì‹  'adjacent sat index' ì‚¬ìš©
                for nbr_id in sat['adjacent sat index']:
                    if nbr_id == -1 or nbr_id not in sat_dict:
                        continue
                    nbr_sat = sat_dict[nbr_id]
                    ax.plot([sat['lon'], nbr_sat['lon']], [sat['lat'], nbr_sat['lat']],
                            color='gray', linewidth=1.0, alpha=0.3, zorder=1)

                # 4. ìœ„ì„± ì¸ë±ìŠ¤ ëª¨ë‘ í‘œì‹œ
                ax.annotate(str(sat['sat_id']), (sat['lon'], sat['lat']), fontsize=13, alpha=0.7, zorder=5)

            # 2. ìœ„ì„± ì‚°ì ë„ (VSG ì˜ì—­ë³„ ìƒ‰ìƒ)
            for sat in sat_list:
                # sat ê°ì²´ì— vsg_idê°€ ì—†ìœ¼ë¯€ë¡œ, VSG ë°ì´í„°ì—ì„œ í•´ë‹¹ sat_idë¥¼ í¬í•¨í•˜ëŠ” VSGë¥¼ ì°¾ì•„ ìƒ‰ìƒì„ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.
                vsg_id_of_sat = next((vsg['vsg_id'] for vsg in vsg_list if sat['sat_id'] in vsg['satellites']),
                                     None)
                color = vsg_colors.get(vsg_id_of_sat, 'blue')  # ê¸°ë³¸ ìƒ‰ìƒ ì„¤ì •

                ax.scatter(sat['lon'], sat['lat'], s=100, color=color, edgecolors='black',
                           linewidths=0.8, alpha=0.6, zorder=2)

                # 3. VNF ìˆ˜í–‰ ìœ„ì„± ê°•ì¡°
                if sat['vnf list']:
                    ax.scatter(sat['lon'], sat['lat'], marker='*', s=80, color='red', edgecolors='black',
                               linewidths=0.8,
                               zorder=4)
                    ax.annotate(f"VNF {sat['vnf list']}", (sat['lon'] + 3.0, sat['lat'] + 2.0),
                                fontsize=13, color='darkred', alpha=0.8, zorder=12)

            if gsfc_record:
                satellite_path = safe_load_path(gsfc_record.get('satellite_path', []))
                processed_path = safe_load_path(gsfc_record.get('processed_satellite_path', []))

                # ì „ì²´ ê²½ë¡œì—ì„œ processed_pathë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ê²½ë¡œ
                # satellite_pathê°€ ì „ì²´ ê²½ë¡œì´ê³  processed_pathê°€ ì§€ë‚˜ì˜¨ ê²½ë¡œë¼ë©´,
                # remaining_pathë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

                # CSV ì €ì¥ ë°©ì‹ì— ë”°ë¼ ì²˜ë¦¬ ë°©ì‹ì´ ë‹¬ë¼ì§.
                # (A) ì „ì²´ ê²½ë¡œì™€ í˜„ì¬ ì¸ë±ìŠ¤ê°€ ì €ì¥ëœ ê²½ìš°
                # (B) ì§€ë‚˜ì˜¨ ê²½ë¡œì™€ ì „ì²´ ê²½ë¡œê°€ ë¶„ë¦¬ë˜ì–´ ì €ì¥ëœ ê²½ìš°

                # ì—¬ê¸°ì„œëŠ” 'processed_satellite_path'ê°€ `gsfc.satellite_path[:gsfc.cur_path_id]`ë¡œ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ,
                # ì „ì²´ ê²½ë¡œì™€ cur_path_idë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                if isinstance(satellite_path, list) or isinstance(processed_path, list):
                    # ì „ì²´ ê²½ë¡œì—ì„œ processed_pathì˜ ê¸¸ì´ë§Œí¼ì´ ì§€ë‚˜ê°”ë‹¤ê³  ê°€ì •
                    cur_path_len = len(processed_path)

                    processed_path_ids = satellite_path[:cur_path_len]
                    remain_path_ids = satellite_path[cur_path_len:]

                    processed_edges = []
                    remaining_edges = []

                    processed_sat_ids = sat_ids(processed_path_ids)
                    remaining_sat_ids = sat_ids(remain_path_ids)
                    all_tracked_sat_ids = list(set(processed_sat_ids + remaining_sat_ids))

                    # A. Processed Path ì—£ì§€ ì¶”ì¶œ
                    if len(processed_path_ids) >= 2:
                        for i in range(len(processed_path_ids) - 1):
                            prev_sat_id = processed_path_ids[i][0]
                            current_sat_id = processed_path_ids[i + 1][0]
                            if current_sat_id != prev_sat_id:
                                processed_edges.append((prev_sat_id, current_sat_id))

                    # B. Remaining Path ì—£ì§€ ì¶”ì¶œ
                    if remain_path_ids:
                        # Processed Pathì™€ Remain Path ì—°ê²° ì—£ì§€
                        if processed_path_ids:
                            last_processed_sat_id = processed_path_ids[-1][0]
                            first_remaining_sat_id = remain_path_ids[0][0]
                            if last_processed_sat_id != first_remaining_sat_id:
                                remaining_edges.append((last_processed_sat_id, first_remaining_sat_id))

                        # ë‚˜ë¨¸ì§€ Remaining Path ì—£ì§€
                        if len(remain_path_ids) >= 2:
                            for i in range(len(remain_path_ids) - 1):
                                prev_sat_id = remain_path_ids[i][0]
                                current_sat_id = remain_path_ids[i + 1][0]
                                if current_sat_id != prev_sat_id:
                                    remaining_edges.append((prev_sat_id, current_sat_id))

                    # í•˜ì´ë¼ì´íŒ… ì‹œê°í™” (NetworkX Gë¥¼ ì‚¬ìš©)

                    # 4-1. ë…¸ë“œ í•˜ì´ë¼ì´íŒ… (ì „ì²´ ê²½ë¡œ ë…¸ë“œ)
                    nx.draw_networkx_nodes(G, pos=sat_positions, nodelist=all_tracked_sat_ids,
                                           node_color='gray', node_size=150, ax=ax)

                    # 4-2. Processed Path ì—£ì§€ (ì´ˆë¡ìƒ‰)
                    nx.draw_networkx_edges(G, pos=sat_positions, edgelist=processed_edges,
                                           edge_color='green', width=2.5, ax=ax)

                    # 4-3. Remaining Path ì—£ì§€ (ë¹¨ê°„ìƒ‰)
                    nx.draw_networkx_edges(G, pos=sat_positions, edgelist=remaining_edges,
                                           edge_color='red', width=2.5, ax=ax)

                    # 4-4. í˜„ì¬ ìœ„ì¹˜ ìœ„ì„± ê°•ì¡°
                    if processed_path_ids:
                        current_sat_id = processed_path_ids[-1][0]
                        nx.draw_networkx_nodes(G, pos=sat_positions, nodelist=[current_sat_id],
                                               node_color='yellow', node_size=200, ax=ax)

            plt.xlabel("Longitude")
            plt.ylabel("Latitude")
            plt.title(f"Network Constellation at {t}ms (GSFC ID: {gsfc_id}, Mode: {mode})")
            plt.grid(True)
            plt.tight_layout()

            fig.canvas.draw()
            width, height = fig.canvas.get_width_height()
            img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
            img = img.reshape((height, width, 3))

            # VideoWriter ì´ˆê¸°í™”
            if video_writer is None:
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                video_writer = cv2.VideoWriter(
                    video_path, fourcc,
                    video_fps,
                    (width, height)
                )

            # OpenCVëŠ” BGRì´ë¼ ë³€í™˜ í›„ write
            frame_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            video_writer.write(frame_bgr)

            plt.close(fig)

            # ë£¨í”„ê°€ ëë‚˜ê³  ë‚˜ì„œ VideoWriter í•´ì œ
        if video_writer is not None:
            video_writer.release()
            print(f"[INFO] Saved video to {video_path}")